{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from darts import TimeSeries, concatenate\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.metrics import mae, mse, mape, rmse, smape\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from darts.models import TiDEModel, BlockRNNModel, TCNModel, TransformerModel, TCNModel, NBEATSModel\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import config\n",
    "\n",
    "freq='2H3T14S'\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"OpenMarsFinal\")\n",
    "pd.options.plotting.backend = \"plotly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(training_file, testing_file):\n",
    "    dataframes = []\n",
    "    for data_file in [training_file, testing_file]:\n",
    "        parser = lambda data_string: datetime.strptime(data_string, '%Y-%m-%d %H:%M:%S')\n",
    "        dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n",
    "                                date_parser=parser)\n",
    "        print(f\"Rows in {data_file}: {len(dataframe)}\")\n",
    "        dataframe.drop(['Ls', 'LT', 'CO2ice'], axis=1, inplace=True)\n",
    "        dataframes.append(dataframe)\n",
    "\n",
    "    return pd.concat(dataframes, axis=0)\n",
    "\n",
    "\n",
    "def preprocess(dataframe):\n",
    "        time = pd.date_range(\"1998-07-15 21:23:39\", periods=len(dataframe), freq=freq)\n",
    "        dataframe.index = time\n",
    "        dataframe = dataframe.drop(['Time'], axis=1)\n",
    "        return dataframe\n",
    "\n",
    "def create_series(dataframe):\n",
    "        series = TimeSeries.from_dataframe(dataframe, time_col=None, value_cols=None, fill_missing_dates=True, freq=freq, fillna_value=None)\n",
    "        return series.astype(np.float32)\n",
    "\n",
    "def create_train_val_test_series(series):\n",
    "        train, temp = series.split_after(0.7)\n",
    "        val, test = temp.split_after(0.67)\n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4698/3478556548.py:5: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in ../data/data_files/insight_openmars_training_time.csv: 72196\n",
      "Rows in ../data/data_files/insight_openmars_test_time.csv: 16364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4698/3478556548.py:5: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_dataset('../data/data_files/insight_openmars_training_time.csv',\n",
    "                         '../data/data_files/insight_openmars_test_time.csv')\n",
    "dataframe = preprocess(dataframe)\n",
    "full_series = create_series(dataframe)\n",
    "train, val, test = create_train_val_test_series(full_series)\n",
    "# print(len(train), len(val), len(test))\n",
    "len(full_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'dust',\n",
       "       'temp'],\n",
       "      dtype='object', name='component')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()  # default uses sklearn's MinMaxScaler\n",
    "full_series = scaler.fit_transform(full_series)\n",
    "train = scaler.fit_transform(train)\n",
    "val = scaler.transform(val)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "lr_scheduler_cls = torch.optim.lr_scheduler.ExponentialLR\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61992 17800 8768\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_block_rnn_model():\n",
    "\n",
    "    # select input and output chunk lengths\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "\n",
    "    # Other hyperparameters\n",
    "    n_rnn_layers = 2\n",
    "    hidden_dim =  30\n",
    "    dropout = 0.25\n",
    "    lr = 0.0005\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "    # build the BlockRNNModel model\n",
    "    model = BlockRNNModel(model = \"LSTM\",\n",
    "                                input_chunk_length= in_len,\n",
    "                                output_chunk_length = out_len,\n",
    "                                n_rnn_layers = n_rnn_layers,\n",
    "                                hidden_dim = hidden_dim,\n",
    "                                batch_size = batch_size,\n",
    "                                model_name=\"BlockRNNModel_84_12\", \n",
    "                                dropout = dropout,\n",
    "                                **common_model_args)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tcn_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "    # Other hyperparameters\n",
    "    kernel_size = 2\n",
    "    num_filters = 6\n",
    "    weight_norm = True\n",
    "    dilation_base = 2\n",
    "    dropout = 0.05\n",
    "    lr = 0.0005\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "    # pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "    # build the TCN model\n",
    "    model = TCNModel(\n",
    "    input_chunk_length= in_len,\n",
    "    output_chunk_length = out_len,\n",
    "    dilation_base = dilation_base,\n",
    "    weight_norm = weight_norm,\n",
    "    kernel_size = kernel_size,\n",
    "    num_filters = num_filters,\n",
    "    model_name = 'TCNModel_84_12',\n",
    "    dropout = dropout,\n",
    "    **common_model_args\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_transformer_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "\n",
    "    # Other hyperparameters\n",
    "\n",
    "    d_model=12\n",
    "    nhead=6\n",
    "\n",
    "    num_encoder_layers=2\n",
    "    num_decoder_layers=4\n",
    "    dim_feedforward=64\n",
    "    dropout = 0.05\n",
    "    lr = 0.0005\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "    # build the Transfofrmer model\n",
    "    model = TransformerModel(\n",
    "    input_chunk_length=in_len,\n",
    "    output_chunk_length=out_len,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout,\n",
    "    activation=\"relu\",\n",
    "    model_name = 'TransformerModel_84_12',\n",
    "    **common_model_args,\n",
    ")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_n_beats_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "    lr = 0.0005\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_blocks=3\n",
    "    num_layers=4\n",
    "    layer_widths=512\n",
    "    dropout = 0.05\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "# build the NBeats model\n",
    "    model = NBEATSModel(\n",
    "        generic_architecture=False,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=layer_widths,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        input_chunk_length= in_len,\n",
    "        output_chunk_length = out_len,\n",
    "        model_name = 'NBEATSModel_84_12',\n",
    "        dropout=dropout,\n",
    "        **common_model_args,\n",
    "\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forecast(model, predict_after_series = val, variable  = 'dust', forecast_type = 'backtest', n = 84, forecast_horizon = 12):\n",
    "    result_accumulator = {}\n",
    "    print(f'For model {model.model_name}')\n",
    "    if forecast_type == 'backtest':\n",
    "        pred_series = model.historical_forecasts(series=full_series, \n",
    "                                        past_covariates=None,\n",
    "                                        future_covariates=None,\n",
    "                                        start = test.start_time(),\n",
    "                                        stride = forecast_horizon,\n",
    "                                        retrain=False,\n",
    "                                        verbose=False, \n",
    "                                        forecast_horizon=forecast_horizon,\n",
    "                                        last_points_only = False\n",
    "                                        )\n",
    "        pred_series = concatenate(pred_series)\n",
    "\n",
    "    else:\n",
    "        pred_series = model.predict(series=predict_after_series, n = n)\n",
    "    test_variable = test[variable]\n",
    "    pred_variable = pred_series[variable]\n",
    "    if variable != 'cloud':\n",
    "\n",
    "        result_accumulator[variable] = {\n",
    "            \"mae\": mae(test_variable, pred_variable),\n",
    "            \"mse\": mse(test_variable, pred_variable),\n",
    "            \"mape\": mape(test_variable, pred_variable),\n",
    "            \"rmse\": rmse(test_variable, pred_variable)\n",
    "        }\n",
    "    else:\n",
    "        result_accumulator[variable] = {\n",
    "            \"mae\": mae(test_variable, pred_variable),\n",
    "            \"mse\": mse(test_variable, pred_variable),\n",
    "            \"rmse\": rmse(test_variable, pred_variable)\n",
    "        }\n",
    "\n",
    "\n",
    "    return result_accumulator, pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(model, mlflow_run_id, test, pred_series, n = 84, type = 'backtest', variable = 'dust'):\n",
    "      all_artifacts = []\n",
    "      if type == 'backtest':\n",
    "            df_to_plot = pd.DataFrame({'Actual': scaler.inverse_transform(test)[variable].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig = df_to_plot.plot(title=f\"{variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig.show()\n",
    "            fig.write_image(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "\n",
    "            df_to_plot_zoom = pd.DataFrame({'Actual': scaler.inverse_transform(test)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series()})\n",
    "            fig2 = df_to_plot_zoom.plot(title=f\"Zoomed {variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig2.show()\n",
    "            fig2.write_image(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "      elif type == 'predict':\n",
    "            df_to_plot = pd.DataFrame({'Actual': scaler.inverse_transform(full_series[pd.Timestamp('2018-06-05T20:07:47'):])[variable].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig = df_to_plot.plot(title=f\"{variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig.show()\n",
    "            fig.write_image(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "\n",
    "            df_to_plot_zoom = pd.DataFrame({'Actual': scaler.inverse_transform(full_series)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series(), \n",
    "                                                model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig2 = df_to_plot_zoom.plot(title=f\"Zoomed {variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig2.show()\n",
    "            fig2.write_image(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "\n",
    "      return all_artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models =    {'BlockRNNModel_84_12': create_block_rnn_model(),\n",
    "#                 'TCNModel_84_12': create_tcn_model(),\n",
    "#                 'TransformerModel_84_12': create_transformer_model(),\n",
    "#                 'NBEATSModel_84_12': create_n_beats_model(),\n",
    "#                   }\n",
    "\n",
    "# all_models =    {'BlockRNNModel_84_12': BlockRNNModel.load_from_checkpoint(model_name = \"BlockRNNModel_84_12\", best=True),\n",
    "#                 'TCNModel_84_12': TCNModel.load_from_checkpoint(model_name =\"TCNModel_84_12\", best=True),\n",
    "#                 'TransformerModel_84_12': TransformerModel.load_from_checkpoint(model_name =\"TransformerModel_84_12\", best=True),\n",
    "#                 'NBEATSModel_84_12': NBEATSModel.load_from_checkpoint(model_name =\"NBEATSModel_84_12\", best=True),\n",
    "#                   }\n",
    "\n",
    "# for model_name, model in all_models.items():\n",
    "#         # detect if a GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         num_workers = 8\n",
    "#     else:\n",
    "#         num_workers = 0\n",
    "\n",
    "#     series = create_series(dataframe)\n",
    "\n",
    "#     # when validating during training, we can use a slightly longer validation\n",
    "#     # set which also contains the first input_chunk_length time steps\n",
    "#     model_val_set = val\n",
    "\n",
    "#     # train the model\n",
    "#     model.fit(\n",
    "#         series=train,\n",
    "#         val_series=model_val_set,\n",
    "#         num_loader_workers=num_workers,\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf8745678564d8293f160c73759ca75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab13f63981a4a5fb4a884e71fa60b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c0bff0b21f49ad87b3e825f9d480ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e33ce6145d4705b4088e2684b3b58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979ae246cf9947a5b88fee773187efb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddcf4b6cc714eccbf2700572d1f3820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f395c8d1d0af4eb4ac87ebb2f3eab5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d735a66ef28b4b2e9cebaf81470c81dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7383dfcc94df4949a7ad10af63ec61e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8707f59d016b422f8e1308005d22b491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3155e9b6b49e406f958d32ff0bed578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fda767f82b04a9d91e027475392c697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b17c8f1abd49a784558c54886429f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f20302760141d190dc2f69103712c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758e78a00c84da089ac22e24a07f7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fb4780eb894ea1a024b31ed6779e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362b58fe9df44593a67e8c9e501b8036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8912d9174064e668f87d5d85ba63e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748d9b9f8a1447d9988ed35b361be4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd98c47fce14a2baa9b22e5c6fd0a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0a16d876894a7996f196431b027c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe767a83df548198d3922376873d6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a1640f9d664ad4a94dfbf79c8d8ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ff709b78734891bca6cba0c021c50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5186967bc143fc8ef3d9c467d6546e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8252ce1090624aad9c58dd3ecf5b4594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d844e1f437a54d9aacabcbadd5ff39e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76011a863c6544aaaafd5abcc33f27d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797a89c58ebf40f2b5acc25518726bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0146a688fac4024beff3f61061f14b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4879b2c710ad48cd901cc485eae670f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0c4cc75f054466a7db122910ba3b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4074b82a1e244c3db9083cf5c94bc566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0d1d85bd5c4fa99c17f45069abaa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13daadb7e39947c8b8b43739dc6b0e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac0df1669034b6c8e22a89e449b49cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfee57fcf3f4c1789f09b0196df884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ee94f0afe24e1285c3076b1d1ae561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdee867048e4ff89205baebb9eec52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model TiDEModel_84_12_HyperOpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a53a97a47db4dbaa248f076a20f7788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_models =    {'BlockRNNModel_84_12_Best': BlockRNNModel.load_from_checkpoint(model_name = \"BlockRNNModel_84_12\", best=True),\n",
    "                'TCNModel_84_12_Best': TCNModel.load_from_checkpoint(model_name =\"TCNModel_84_12\", best=True),\n",
    "                'TransformerModel_84_12_Best': TransformerModel.load_from_checkpoint(model_name =\"TransformerModel_84_12\", best=True),\n",
    "                'NBEATSModel_84_12_Best': NBEATSModel.load_from_checkpoint(model_name =\"NBEATSModel_84_12\", best=True),\n",
    "                'TiDEModel_84_12_Best': TiDEModel.load_from_checkpoint(model_name = 'TiDEModel_84_12_HyperOpt', best = True)\n",
    "                  }\n",
    "# trained_models =    {\n",
    "#                 'NBEATSModel_84_12_HyperOpt': NBEATSModel.load_from_checkpoint(model_name =\"NBEATSModel_84_12_HyperOpt\", best=True),\n",
    "#                   }\n",
    "\n",
    "\n",
    "all_variables = ['dust', 'Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'temp']\n",
    "# all_variables = ['dust']\n",
    "\n",
    "types = ['backtest', 'predict']\n",
    "all_metrics = {}\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    with mlflow.start_run(run_name=model.model_name) as run:\n",
    "        all_artifacts = []\n",
    "        mlflow.set_tag(\"Model_Name\", model.model_name)\n",
    "        mlflow.log_params(model.model_params)\n",
    "        for variable in all_variables:\n",
    "            for type in types:\n",
    "                metrics = {}\n",
    "                if type == 'predict':\n",
    "                    series = full_series[:pd.Timestamp('2018-06-05T20:07:47')]\n",
    "                    eval_results, pred_series = forecast(model, predict_after_series=series,\n",
    "                                                          variable=variable, forecast_type=type)\n",
    "                    \n",
    "                    for var, metric_dict in eval_results.items():\n",
    "                        for metric_name, val in metric_dict.items():\n",
    "                            all_metrics[f'{model.model_name}_{metric_name}_{var}_{type}'] = val\n",
    "                            mlflow.log_metric(f'{metric_name}_{var}_{type}', val)\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    series = test\n",
    "                    eval_results, pred_series = forecast(model, predict_after_series=series,\n",
    "                                                          variable=variable, forecast_type=type)\n",
    "                    for var, metric_dict in eval_results.items():\n",
    "                        for metric_name, val in metric_dict.items():\n",
    "                            all_metrics[f'{model.model_name}_{metric_name}_{var}_{type}'] = val\n",
    "                            mlflow.log_metric(f'{metric_name}_{var}_{type}', val)\n",
    "                # print(metrics)\n",
    "                # with open(f'../metrics/metrics_{model.model_name}_{variable}_{type}.json', 'w') as f:\n",
    "                #     json.dump(metrics, f)\n",
    "                # mlflow.log_table(data=metrics, artifact_file=f'metrics_{model.model_name}_{variable}_{type}.json')\n",
    "                # print(eval_results)\n",
    "            #     for var, metric_dict in eval_results.items():\n",
    "            #         mlflow.log_metrics(metric_dict)\n",
    "                    # for metric_name, val in metric_dict.items():\n",
    "                    #     mlflow.log_metrics(metric)\n",
    "                # mlflow.log_table(data = eval_results, artifact_file = f'metrics_{model.model_name}_{variable}_{type}.json')\n",
    "                # artifacts = plotting(model, run.info.run_id, test, pred_series, type = type,  variable = variable)\n",
    "                # all_artifacts.extend(artifacts)\n",
    "                # columns = ['Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'dust', 'temp']\n",
    "                # predict_df = scaler.inverse_transform(pred_series).pd_dataframe()\n",
    "                # predicted_file_nm =f'{model.model_name}_{type}'\n",
    "                # final_path = f'/home/ubuntu/OpenMarsML/data/predicted_data/{predicted_file_nm}.csv'\n",
    "                # print(f'Going to save predictions of model {model.model_name} to file {final_path}')\n",
    "                # predict_df.to_csv(final_path)\n",
    "\n",
    "        # for artifact in all_artifacts:\n",
    "        #     print(artifact)\n",
    "        #     mlflow.log_artifact(artifact)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_to_predict = full_series[:pd.Timestamp('2018-06-05T20:07:47')]\n",
    "# series_predicted_actual = full_series[:pd.Timestamp('2018-06-05 22:11:01')]\n",
    "# final_path = f'/home/ubuntu/OpenMarsML/data/data_files/series_to_predict.csv'\n",
    "# series_to_predict.to_csv(f'/home/ubuntu/OpenMarsML/data/data_files/series_to_predict.csv')\n",
    "# series_predicted_actual.to_csv(f'/home/ubuntu/OpenMarsML/data/data_files/predicted_series_actual_vals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BlockRNNModel_84_12_mae_dust_backtest': 0.04043857,\n",
       " 'BlockRNNModel_84_12_mse_dust_backtest': 0.010832378,\n",
       " 'BlockRNNModel_84_12_mape_dust_backtest': 23.08908998966217,\n",
       " 'BlockRNNModel_84_12_rmse_dust_backtest': 0.10407871,\n",
       " 'BlockRNNModel_84_12_mae_dust_predict': 0.47711036,\n",
       " 'BlockRNNModel_84_12_mse_dust_predict': 0.26179186,\n",
       " 'BlockRNNModel_84_12_mape_dust_predict': 77.92339324951172,\n",
       " 'BlockRNNModel_84_12_rmse_dust_predict': 0.511656,\n",
       " 'BlockRNNModel_84_12_mae_Tsurf_backtest': 0.024764007,\n",
       " 'BlockRNNModel_84_12_mse_Tsurf_backtest': 0.0011659008,\n",
       " 'BlockRNNModel_84_12_mape_Tsurf_backtest': 11.06971725821495,\n",
       " 'BlockRNNModel_84_12_rmse_Tsurf_backtest': 0.034145292,\n",
       " 'BlockRNNModel_84_12_mae_Tsurf_predict': 0.117779106,\n",
       " 'BlockRNNModel_84_12_mse_Tsurf_predict': 0.017748294,\n",
       " 'BlockRNNModel_84_12_mape_Tsurf_predict': 27.09687650203705,\n",
       " 'BlockRNNModel_84_12_rmse_Tsurf_predict': 0.13322273,\n",
       " 'BlockRNNModel_84_12_mae_Psurf_backtest': 0.027591374,\n",
       " 'BlockRNNModel_84_12_mse_Psurf_backtest': 0.0016589984,\n",
       " 'BlockRNNModel_84_12_mape_Psurf_backtest': 6.019645184278488,\n",
       " 'BlockRNNModel_84_12_rmse_Psurf_backtest': 0.040730804,\n",
       " 'BlockRNNModel_84_12_mae_Psurf_predict': 0.06572796,\n",
       " 'BlockRNNModel_84_12_mse_Psurf_predict': 0.0060510347,\n",
       " 'BlockRNNModel_84_12_mape_Psurf_predict': 23.238804936408997,\n",
       " 'BlockRNNModel_84_12_rmse_Psurf_predict': 0.0777884,\n",
       " 'BlockRNNModel_84_12_mae_cloud_backtest': 0.024159865,\n",
       " 'BlockRNNModel_84_12_mse_cloud_backtest': 0.0010927896,\n",
       " 'BlockRNNModel_84_12_rmse_cloud_backtest': 0.03305737,\n",
       " 'BlockRNNModel_84_12_mae_cloud_predict': 0.025491558,\n",
       " 'BlockRNNModel_84_12_mse_cloud_predict': 0.0009030749,\n",
       " 'BlockRNNModel_84_12_rmse_cloud_predict': 0.030051205,\n",
       " 'BlockRNNModel_84_12_mae_vapour_backtest': 0.014787294,\n",
       " 'BlockRNNModel_84_12_mse_vapour_backtest': 0.00042018617,\n",
       " 'BlockRNNModel_84_12_mape_vapour_backtest': 5.606592074036598,\n",
       " 'BlockRNNModel_84_12_rmse_vapour_backtest': 0.020498443,\n",
       " 'BlockRNNModel_84_12_mae_vapour_predict': 0.027054701,\n",
       " 'BlockRNNModel_84_12_mse_vapour_predict': 0.0010432762,\n",
       " 'BlockRNNModel_84_12_mape_vapour_predict': 9.633656591176987,\n",
       " 'BlockRNNModel_84_12_rmse_vapour_predict': 0.032299787,\n",
       " 'BlockRNNModel_84_12_mae_u_wind_backtest': 0.06462918,\n",
       " 'BlockRNNModel_84_12_mse_u_wind_backtest': 0.008134814,\n",
       " 'BlockRNNModel_84_12_mape_u_wind_backtest': 16.665704548358917,\n",
       " 'BlockRNNModel_84_12_rmse_u_wind_backtest': 0.090193205,\n",
       " 'BlockRNNModel_84_12_mae_u_wind_predict': 0.09552282,\n",
       " 'BlockRNNModel_84_12_mse_u_wind_predict': 0.015635582,\n",
       " 'BlockRNNModel_84_12_mape_u_wind_predict': 22.75327891111374,\n",
       " 'BlockRNNModel_84_12_rmse_u_wind_predict': 0.12504232,\n",
       " 'BlockRNNModel_84_12_mae_v_wind_backtest': 0.045111116,\n",
       " 'BlockRNNModel_84_12_mse_v_wind_backtest': 0.0038368574,\n",
       " 'BlockRNNModel_84_12_mape_v_wind_backtest': 9.183912724256516,\n",
       " 'BlockRNNModel_84_12_rmse_v_wind_backtest': 0.061942372,\n",
       " 'BlockRNNModel_84_12_mae_v_wind_predict': 0.06915828,\n",
       " 'BlockRNNModel_84_12_mse_v_wind_predict': 0.007721337,\n",
       " 'BlockRNNModel_84_12_mape_v_wind_predict': 15.543611347675323,\n",
       " 'BlockRNNModel_84_12_rmse_v_wind_predict': 0.08787114,\n",
       " 'BlockRNNModel_84_12_mae_temp_backtest': 0.040898643,\n",
       " 'BlockRNNModel_84_12_mse_temp_backtest': 0.002821805,\n",
       " 'BlockRNNModel_84_12_mape_temp_backtest': 8.394428342580795,\n",
       " 'BlockRNNModel_84_12_rmse_temp_backtest': 0.053120665,\n",
       " 'BlockRNNModel_84_12_mae_temp_predict': 0.1528706,\n",
       " 'BlockRNNModel_84_12_mse_temp_predict': 0.029022373,\n",
       " 'BlockRNNModel_84_12_mape_temp_predict': 20.323142409324646,\n",
       " 'BlockRNNModel_84_12_rmse_temp_predict': 0.17035954,\n",
       " 'TCNModel_84_12_mae_dust_backtest': 0.040521283,\n",
       " 'TCNModel_84_12_mse_dust_backtest': 0.01114268,\n",
       " 'TCNModel_84_12_mape_dust_backtest': 27.84445881843567,\n",
       " 'TCNModel_84_12_rmse_dust_backtest': 0.105558895,\n",
       " 'TCNModel_84_12_mae_dust_predict': 0.47869024,\n",
       " 'TCNModel_84_12_mse_dust_predict': 0.264738,\n",
       " 'TCNModel_84_12_mape_dust_predict': 77.86687016487122,\n",
       " 'TCNModel_84_12_rmse_dust_predict': 0.51452696,\n",
       " 'TCNModel_84_12_mae_Tsurf_backtest': 0.0060271346,\n",
       " 'TCNModel_84_12_mse_Tsurf_backtest': 0.00011974169,\n",
       " 'TCNModel_84_12_mape_Tsurf_backtest': 2.539270929992199,\n",
       " 'TCNModel_84_12_rmse_Tsurf_backtest': 0.010942655,\n",
       " 'TCNModel_84_12_mae_Tsurf_predict': 0.091665305,\n",
       " 'TCNModel_84_12_mse_Tsurf_predict': 0.01061859,\n",
       " 'TCNModel_84_12_mape_Tsurf_predict': 20.504721999168396,\n",
       " 'TCNModel_84_12_rmse_Tsurf_predict': 0.103046544,\n",
       " 'TCNModel_84_12_mae_Psurf_backtest': 0.013014884,\n",
       " 'TCNModel_84_12_mse_Psurf_backtest': 0.00029517416,\n",
       " 'TCNModel_84_12_mape_Psurf_backtest': 2.672090195119381,\n",
       " 'TCNModel_84_12_rmse_Psurf_backtest': 0.017180633,\n",
       " 'TCNModel_84_12_mae_Psurf_predict': 0.050964423,\n",
       " 'TCNModel_84_12_mse_Psurf_predict': 0.0049127983,\n",
       " 'TCNModel_84_12_mape_Psurf_predict': 19.724009931087494,\n",
       " 'TCNModel_84_12_rmse_Psurf_predict': 0.07009136,\n",
       " 'TCNModel_84_12_mae_cloud_backtest': 0.03232136,\n",
       " 'TCNModel_84_12_mse_cloud_backtest': 0.0016458227,\n",
       " 'TCNModel_84_12_rmse_cloud_backtest': 0.04056874,\n",
       " 'TCNModel_84_12_mae_cloud_predict': 0.016253602,\n",
       " 'TCNModel_84_12_mse_cloud_predict': 0.0002924553,\n",
       " 'TCNModel_84_12_rmse_cloud_predict': 0.017101325,\n",
       " 'TCNModel_84_12_mae_vapour_backtest': 0.011832757,\n",
       " 'TCNModel_84_12_mse_vapour_backtest': 0.00027720802,\n",
       " 'TCNModel_84_12_mape_vapour_backtest': 4.563497379422188,\n",
       " 'TCNModel_84_12_rmse_vapour_backtest': 0.016649565,\n",
       " 'TCNModel_84_12_mae_vapour_predict': 0.020622298,\n",
       " 'TCNModel_84_12_mse_vapour_predict': 0.0007880973,\n",
       " 'TCNModel_84_12_mape_vapour_predict': 7.166147977113724,\n",
       " 'TCNModel_84_12_rmse_vapour_predict': 0.02807307,\n",
       " 'TCNModel_84_12_mae_u_wind_backtest': 0.061245296,\n",
       " 'TCNModel_84_12_mse_u_wind_backtest': 0.0058382554,\n",
       " 'TCNModel_84_12_mape_u_wind_backtest': 15.247796475887299,\n",
       " 'TCNModel_84_12_rmse_u_wind_backtest': 0.076408476,\n",
       " 'TCNModel_84_12_mae_u_wind_predict': 0.088278115,\n",
       " 'TCNModel_84_12_mse_u_wind_predict': 0.012863205,\n",
       " 'TCNModel_84_12_mape_u_wind_predict': 20.293110609054565,\n",
       " 'TCNModel_84_12_rmse_u_wind_predict': 0.11341607,\n",
       " 'TCNModel_84_12_mae_v_wind_backtest': 0.03344531,\n",
       " 'TCNModel_84_12_mse_v_wind_backtest': 0.002378435,\n",
       " 'TCNModel_84_12_mape_v_wind_backtest': 7.2022005915641785,\n",
       " 'TCNModel_84_12_rmse_v_wind_backtest': 0.048769202,\n",
       " 'TCNModel_84_12_mae_v_wind_predict': 0.06876411,\n",
       " 'TCNModel_84_12_mse_v_wind_predict': 0.009212097,\n",
       " 'TCNModel_84_12_mape_v_wind_predict': 16.210491955280304,\n",
       " 'TCNModel_84_12_rmse_v_wind_predict': 0.09597967,\n",
       " 'TCNModel_84_12_mae_temp_backtest': 0.041341297,\n",
       " 'TCNModel_84_12_mse_temp_backtest': 0.0027147701,\n",
       " 'TCNModel_84_12_mape_temp_backtest': 8.592583984136581,\n",
       " 'TCNModel_84_12_rmse_temp_backtest': 0.052103456,\n",
       " 'TCNModel_84_12_mae_temp_predict': 0.14832702,\n",
       " 'TCNModel_84_12_mse_temp_predict': 0.026503418,\n",
       " 'TCNModel_84_12_mape_temp_predict': 19.828324019908905,\n",
       " 'TCNModel_84_12_rmse_temp_predict': 0.1627987,\n",
       " 'TransformerModel_84_12_mae_dust_backtest': 0.04307562,\n",
       " 'TransformerModel_84_12_mse_dust_backtest': 0.010092018,\n",
       " 'TransformerModel_84_12_mape_dust_backtest': 28.457099199295044,\n",
       " 'TransformerModel_84_12_rmse_dust_backtest': 0.10045904,\n",
       " 'TransformerModel_84_12_mae_dust_predict': 0.48727694,\n",
       " 'TransformerModel_84_12_mse_dust_predict': 0.27396363,\n",
       " 'TransformerModel_84_12_mape_dust_predict': 79.30952906608582,\n",
       " 'TransformerModel_84_12_rmse_dust_predict': 0.5234153,\n",
       " 'TransformerModel_84_12_mae_Tsurf_backtest': 0.028058423,\n",
       " 'TransformerModel_84_12_mse_Tsurf_backtest': 0.0013121906,\n",
       " 'TransformerModel_84_12_mape_Tsurf_backtest': 14.253784716129303,\n",
       " 'TransformerModel_84_12_rmse_Tsurf_backtest': 0.03622417,\n",
       " 'TransformerModel_84_12_mae_Tsurf_predict': 0.11961879,\n",
       " 'TransformerModel_84_12_mse_Tsurf_predict': 0.018679198,\n",
       " 'TransformerModel_84_12_mape_Tsurf_predict': 28.99518609046936,\n",
       " 'TransformerModel_84_12_rmse_Tsurf_predict': 0.13667186,\n",
       " 'TransformerModel_84_12_mae_Psurf_backtest': 0.027852139,\n",
       " 'TransformerModel_84_12_mse_Psurf_backtest': 0.0016685247,\n",
       " 'TransformerModel_84_12_mape_Psurf_backtest': 6.0112472623586655,\n",
       " 'TransformerModel_84_12_rmse_Psurf_backtest': 0.040847577,\n",
       " 'TransformerModel_84_12_mae_Psurf_predict': 0.07315775,\n",
       " 'TransformerModel_84_12_mse_Psurf_predict': 0.0073586497,\n",
       " 'TransformerModel_84_12_mape_Psurf_predict': 23.947806656360626,\n",
       " 'TransformerModel_84_12_rmse_Psurf_predict': 0.08578257,\n",
       " 'TransformerModel_84_12_mae_cloud_backtest': 0.02704156,\n",
       " 'TransformerModel_84_12_mse_cloud_backtest': 0.0013472924,\n",
       " 'TransformerModel_84_12_rmse_cloud_backtest': 0.036705483,\n",
       " 'TransformerModel_84_12_mae_cloud_predict': 0.011589389,\n",
       " 'TransformerModel_84_12_mse_cloud_predict': 0.00018211042,\n",
       " 'TransformerModel_84_12_rmse_cloud_predict': 0.01349483,\n",
       " 'TransformerModel_84_12_mae_vapour_backtest': 0.017419957,\n",
       " 'TransformerModel_84_12_mse_vapour_backtest': 0.00048301983,\n",
       " 'TransformerModel_84_12_mape_vapour_backtest': 6.883179396390915,\n",
       " 'TransformerModel_84_12_rmse_vapour_backtest': 0.021977711,\n",
       " 'TransformerModel_84_12_mae_vapour_predict': 0.015191992,\n",
       " 'TransformerModel_84_12_mse_vapour_predict': 0.00033195465,\n",
       " 'TransformerModel_84_12_mape_vapour_predict': 5.130632221698761,\n",
       " 'TransformerModel_84_12_rmse_vapour_predict': 0.018219622,\n",
       " 'TransformerModel_84_12_mae_u_wind_backtest': 0.06049103,\n",
       " 'TransformerModel_84_12_mse_u_wind_backtest': 0.007419187,\n",
       " 'TransformerModel_84_12_mape_u_wind_backtest': 15.421667695045471,\n",
       " 'TransformerModel_84_12_rmse_u_wind_backtest': 0.0861347,\n",
       " 'TransformerModel_84_12_mae_u_wind_predict': 0.0913716,\n",
       " 'TransformerModel_84_12_mse_u_wind_predict': 0.014885163,\n",
       " 'TransformerModel_84_12_mape_u_wind_predict': 21.108238399028778,\n",
       " 'TransformerModel_84_12_rmse_u_wind_predict': 0.12200477,\n",
       " 'TransformerModel_84_12_mae_v_wind_backtest': 0.046785027,\n",
       " 'TransformerModel_84_12_mse_v_wind_backtest': 0.0039440994,\n",
       " 'TransformerModel_84_12_mape_v_wind_backtest': 9.487319737672806,\n",
       " 'TransformerModel_84_12_rmse_v_wind_backtest': 0.06280207,\n",
       " 'TransformerModel_84_12_mae_v_wind_predict': 0.0750399,\n",
       " 'TransformerModel_84_12_mse_v_wind_predict': 0.009917955,\n",
       " 'TransformerModel_84_12_mape_v_wind_predict': 17.306305468082428,\n",
       " 'TransformerModel_84_12_rmse_v_wind_predict': 0.09958893,\n",
       " 'TransformerModel_84_12_mae_temp_backtest': 0.0406086,\n",
       " 'TransformerModel_84_12_mse_temp_backtest': 0.0028210657,\n",
       " 'TransformerModel_84_12_mape_temp_backtest': 8.50706622004509,\n",
       " 'TransformerModel_84_12_rmse_temp_backtest': 0.053113706,\n",
       " 'TransformerModel_84_12_mae_temp_predict': 0.15102096,\n",
       " 'TransformerModel_84_12_mse_temp_predict': 0.028686296,\n",
       " 'TransformerModel_84_12_mape_temp_predict': 20.027008652687073,\n",
       " 'TransformerModel_84_12_rmse_temp_predict': 0.1693703,\n",
       " 'NBEATSModel_84_12_mae_dust_backtest': 0.042682283,\n",
       " 'NBEATSModel_84_12_mse_dust_backtest': 0.012543831,\n",
       " 'NBEATSModel_84_12_mape_dust_backtest': 32.12507963180542,\n",
       " 'NBEATSModel_84_12_rmse_dust_backtest': 0.11199924,\n",
       " 'NBEATSModel_84_12_mae_dust_predict': 0.48003474,\n",
       " 'NBEATSModel_84_12_mse_dust_predict': 0.2665723,\n",
       " 'NBEATSModel_84_12_mape_dust_predict': 77.99035310745239,\n",
       " 'NBEATSModel_84_12_rmse_dust_predict': 0.5163064,\n",
       " 'NBEATSModel_84_12_mae_Tsurf_backtest': 0.018798763,\n",
       " 'NBEATSModel_84_12_mse_Tsurf_backtest': 0.0006668286,\n",
       " 'NBEATSModel_84_12_mape_Tsurf_backtest': 8.710120618343353,\n",
       " 'NBEATSModel_84_12_rmse_Tsurf_backtest': 0.025823025,\n",
       " 'NBEATSModel_84_12_mae_Tsurf_predict': 0.12916571,\n",
       " 'NBEATSModel_84_12_mse_Tsurf_predict': 0.020753566,\n",
       " 'NBEATSModel_84_12_mape_Tsurf_predict': 28.390827775001526,\n",
       " 'NBEATSModel_84_12_rmse_Tsurf_predict': 0.14406098,\n",
       " 'NBEATSModel_84_12_mae_Psurf_backtest': 0.032100983,\n",
       " 'NBEATSModel_84_12_mse_Psurf_backtest': 0.0016309256,\n",
       " 'NBEATSModel_84_12_mape_Psurf_backtest': 6.161771342158318,\n",
       " 'NBEATSModel_84_12_rmse_Psurf_backtest': 0.04038472,\n",
       " 'NBEATSModel_84_12_mae_Psurf_predict': 0.06554564,\n",
       " 'NBEATSModel_84_12_mse_Psurf_predict': 0.0060869358,\n",
       " 'NBEATSModel_84_12_mape_Psurf_predict': 22.240349650382996,\n",
       " 'NBEATSModel_84_12_rmse_Psurf_predict': 0.078018814,\n",
       " 'NBEATSModel_84_12_mae_cloud_backtest': 0.024252247,\n",
       " 'NBEATSModel_84_12_mse_cloud_backtest': 0.0010775971,\n",
       " 'NBEATSModel_84_12_rmse_cloud_backtest': 0.032826774,\n",
       " 'NBEATSModel_84_12_mae_cloud_predict': 0.014928525,\n",
       " 'NBEATSModel_84_12_mse_cloud_predict': 0.00032813888,\n",
       " 'NBEATSModel_84_12_rmse_cloud_predict': 0.018114604,\n",
       " 'NBEATSModel_84_12_mae_vapour_backtest': 0.021512885,\n",
       " 'NBEATSModel_84_12_mse_vapour_backtest': 0.0007325208,\n",
       " 'NBEATSModel_84_12_mape_vapour_backtest': 8.133912831544876,\n",
       " 'NBEATSModel_84_12_rmse_vapour_backtest': 0.027065123,\n",
       " 'NBEATSModel_84_12_mae_vapour_predict': 0.013873008,\n",
       " 'NBEATSModel_84_12_mse_vapour_predict': 0.0002997911,\n",
       " 'NBEATSModel_84_12_mape_vapour_predict': 4.664641246199608,\n",
       " 'NBEATSModel_84_12_rmse_vapour_predict': 0.017314477,\n",
       " 'NBEATSModel_84_12_mae_u_wind_backtest': 0.05345306,\n",
       " 'NBEATSModel_84_12_mse_u_wind_backtest': 0.005633303,\n",
       " 'NBEATSModel_84_12_mape_u_wind_backtest': 13.761498034000397,\n",
       " 'NBEATSModel_84_12_rmse_u_wind_backtest': 0.07505533,\n",
       " 'NBEATSModel_84_12_mae_u_wind_predict': 0.09346444,\n",
       " 'NBEATSModel_84_12_mse_u_wind_predict': 0.017537965,\n",
       " 'NBEATSModel_84_12_mape_u_wind_predict': 23.6727237701416,\n",
       " 'NBEATSModel_84_12_rmse_u_wind_predict': 0.13243099,\n",
       " 'NBEATSModel_84_12_mae_v_wind_backtest': 0.037873566,\n",
       " 'NBEATSModel_84_12_mse_v_wind_backtest': 0.0027800684,\n",
       " 'NBEATSModel_84_12_mape_v_wind_backtest': 7.700509577989578,\n",
       " 'NBEATSModel_84_12_rmse_v_wind_backtest': 0.052726354,\n",
       " 'NBEATSModel_84_12_mae_v_wind_predict': 0.0546584,\n",
       " 'NBEATSModel_84_12_mse_v_wind_predict': 0.004687348,\n",
       " 'NBEATSModel_84_12_mape_v_wind_predict': 11.488060653209686,\n",
       " 'NBEATSModel_84_12_rmse_v_wind_predict': 0.06846421,\n",
       " 'NBEATSModel_84_12_mae_temp_backtest': 0.046962712,\n",
       " 'NBEATSModel_84_12_mse_temp_backtest': 0.0035104791,\n",
       " 'NBEATSModel_84_12_mape_temp_backtest': 9.997031837701797,\n",
       " 'NBEATSModel_84_12_rmse_temp_backtest': 0.059249297,\n",
       " 'NBEATSModel_84_12_mae_temp_predict': 0.16463897,\n",
       " 'NBEATSModel_84_12_mse_temp_predict': 0.0314946,\n",
       " 'NBEATSModel_84_12_mape_temp_predict': 22.30733186006546,\n",
       " 'NBEATSModel_84_12_rmse_temp_predict': 0.17746718,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_dust_backtest': 0.048075736,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_dust_backtest': 0.009547468,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_dust_backtest': 37.48764395713806,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_dust_backtest': 0.097711146,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_dust_predict': 0.45470366,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_dust_predict': 0.241495,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_dust_predict': 73.22906851768494,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_dust_predict': 0.4914214,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_Tsurf_backtest': 0.0069850828,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_Tsurf_backtest': 0.0001592282,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_Tsurf_backtest': 2.987520769238472,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_Tsurf_backtest': 0.012618566,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_Tsurf_predict': 0.105735525,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_Tsurf_predict': 0.013835582,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_Tsurf_predict': 23.804347217082977,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_Tsurf_predict': 0.11762475,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_Psurf_backtest': 0.011818463,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_Psurf_backtest': 0.00025474632,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_Psurf_backtest': 2.4834059178829193,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_Psurf_backtest': 0.015960775,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_Psurf_predict': 0.051515523,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_Psurf_predict': 0.004207643,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_Psurf_predict': 19.64634656906128,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_Psurf_predict': 0.06486635,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_cloud_backtest': 0.012591934,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_cloud_backtest': 0.00054254686,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_cloud_backtest': 0.023292635,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_cloud_predict': 0.0013978216,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_cloud_predict': 3.3866957e-06,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_cloud_predict': 0.0018402977,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_vapour_backtest': 0.010047767,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_vapour_backtest': 0.00018015796,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_vapour_backtest': 3.8418661803007126,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_vapour_backtest': 0.013422294,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_vapour_predict': 0.01414299,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_vapour_predict': 0.00033772914,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_vapour_predict': 5.048928782343864,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_vapour_predict': 0.018377408,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_u_wind_backtest': 0.06647341,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_u_wind_backtest': 0.006098723,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_u_wind_backtest': 16.143545508384705,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_u_wind_backtest': 0.07809432,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_u_wind_predict': 0.0905095,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_u_wind_predict': 0.013378228,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_u_wind_predict': 20.928126573562622,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_u_wind_predict': 0.11566429,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_v_wind_backtest': 0.028503213,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_v_wind_backtest': 0.0016891748,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_v_wind_backtest': 5.80127127468586,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_v_wind_backtest': 0.04109957,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_v_wind_predict': 0.08217764,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_v_wind_predict': 0.01048048,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_v_wind_predict': 17.267775535583496,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_v_wind_predict': 0.10237422,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_temp_backtest': 0.029441364,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_temp_backtest': 0.0014499419,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_temp_backtest': 6.265120953321457,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_temp_backtest': 0.038078103,\n",
       " 'TiDEModel_84_12_HyperOpt_mae_temp_predict': 0.094013214,\n",
       " 'TiDEModel_84_12_HyperOpt_mse_temp_predict': 0.01173887,\n",
       " 'TiDEModel_84_12_HyperOpt_mape_temp_predict': 12.500135600566864,\n",
       " 'TiDEModel_84_12_HyperOpt_rmse_temp_predict': 0.10834607}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
