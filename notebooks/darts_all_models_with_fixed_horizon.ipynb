{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from darts import TimeSeries, concatenate\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.metrics import mae, mse, mape, rmse, smape\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from darts.models import RNNModel, BlockRNNModel, TCNModel, TransformerModel, TCNModel, NBEATSModel\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import config\n",
    "\n",
    "freq='2H3T14S'\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"OpenMarsHyperOptFixedHorizon\")\n",
    "pd.options.plotting.backend = \"plotly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(training_file, testing_file):\n",
    "    dataframes = []\n",
    "    for data_file in [training_file, testing_file]:\n",
    "        parser = lambda data_string: datetime.strptime(data_string, '%Y-%m-%d %H:%M:%S')\n",
    "        dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n",
    "                                date_parser=parser)\n",
    "        print(f\"Rows in {data_file}: {len(dataframe)}\")\n",
    "        dataframe.drop(['Ls', 'LT', 'CO2ice'], axis=1, inplace=True)\n",
    "        dataframes.append(dataframe)\n",
    "\n",
    "    return pd.concat(dataframes, axis=0)\n",
    "\n",
    "\n",
    "def preprocess(dataframe):\n",
    "        time = pd.date_range(\"1998-07-15 21:23:39\", periods=len(dataframe), freq=freq)\n",
    "        dataframe.index = time\n",
    "        dataframe = dataframe.drop(['Time'], axis=1)\n",
    "        return dataframe\n",
    "\n",
    "def create_series(dataframe):\n",
    "        series = TimeSeries.from_dataframe(dataframe, time_col=None, value_cols=None, fill_missing_dates=True, freq=freq, fillna_value=None)\n",
    "        return series.astype(np.float32)\n",
    "\n",
    "def create_train_val_test_series(series):\n",
    "        train, temp = series.split_after(0.7)\n",
    "        val, test = temp.split_after(0.67)\n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1346/3478556548.py:5: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in ../data/data_files/insight_openmars_training_time.csv: 72196\n",
      "Rows in ../data/data_files/insight_openmars_test_time.csv: 16364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1346/3478556548.py:5: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  dataframe = pd.read_csv(data_file, parse_dates=['Time'],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_dataset('../data/data_files/insight_openmars_training_time.csv',\n",
    "                         '../data/data_files/insight_openmars_test_time.csv')\n",
    "dataframe = preprocess(dataframe)\n",
    "full_series = create_series(dataframe)\n",
    "train, val, test = create_train_val_test_series(full_series)\n",
    "# print(len(train), len(val), len(test))\n",
    "len(full_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'dust',\n",
       "       'temp'],\n",
       "      dtype='object', name='component')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()  # default uses sklearn's MinMaxScaler\n",
    "full_series = scaler.fit_transform(full_series)\n",
    "train = scaler.fit_transform(train)\n",
    "val = scaler.transform(val)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "lr_scheduler_cls = torch.optim.lr_scheduler.ExponentialLR\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61992 17800 8768\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_block_rnn_model():\n",
    "\n",
    "    # select input and output chunk lengths\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "\n",
    "    # Other hyperparameters\n",
    "    n_rnn_layers = 2\n",
    "    hidden_dim =  30\n",
    "    dropout = 0.25\n",
    "    lr = 0.0005\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "    # build the BlockRNNModel model\n",
    "    model = BlockRNNModel(model = \"LSTM\",\n",
    "                                input_chunk_length= in_len,\n",
    "                                output_chunk_length = out_len,\n",
    "                                n_rnn_layers = n_rnn_layers,\n",
    "                                hidden_dim = hidden_dim,\n",
    "                                batch_size = batch_size,\n",
    "                                model_name=\"BlockRNNModel_84_12\", \n",
    "                                dropout = dropout,\n",
    "                                **common_model_args)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_tcn_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "    # Other hyperparameters\n",
    "    kernel_size = 2\n",
    "    num_filters = 6\n",
    "    weight_norm = True\n",
    "    dilation_base = 2\n",
    "    dropout = 0.05\n",
    "    lr = 0.0005\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "    # pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "    # build the TCN model\n",
    "    model = TCNModel(\n",
    "    input_chunk_length= in_len,\n",
    "    output_chunk_length = out_len,\n",
    "    dilation_base = dilation_base,\n",
    "    weight_norm = weight_norm,\n",
    "    kernel_size = kernel_size,\n",
    "    num_filters = num_filters,\n",
    "    model_name = 'TCNModel_84_12',\n",
    "    dropout = dropout,\n",
    "    **common_model_args\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_transformer_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "\n",
    "    # Other hyperparameters\n",
    "\n",
    "    d_model=12\n",
    "    nhead=6\n",
    "\n",
    "    num_encoder_layers=2\n",
    "    num_decoder_layers=4\n",
    "    dim_feedforward=64\n",
    "    dropout = 0.05\n",
    "    lr = 0.0005\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "    # build the Transfofrmer model\n",
    "    model = TransformerModel(\n",
    "    input_chunk_length=in_len,\n",
    "    output_chunk_length=out_len,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout,\n",
    "    activation=\"relu\",\n",
    "    model_name = 'TransformerModel_84_12',\n",
    "    **common_model_args,\n",
    ")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_n_beats_model():\n",
    "    in_len = 84\n",
    "    out_len =  12\n",
    "    batch_size = 96\n",
    "    lr = 0.0005\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_blocks=3\n",
    "    num_layers=4\n",
    "    layer_widths=512\n",
    "    dropout = 0.05\n",
    "\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0008, patience=3, verbose=False)\n",
    "    callbacks = [early_stopper]\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    \"gradient_clip_val\": 1,\n",
    "    \"max_epochs\": 50,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    common_model_args = {\n",
    "        \"optimizer_kwargs\": {'lr': lr},\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": config.lr_scheduler_kwargs,\n",
    "        \"likelihood\": None,  # use a likelihood for probabilistic forecasts\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "\n",
    "    }\n",
    "\n",
    "# build the NBeats model\n",
    "    model = NBEATSModel(\n",
    "        generic_architecture=False,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=layer_widths,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        input_chunk_length= in_len,\n",
    "        output_chunk_length = out_len,\n",
    "        model_name = 'NBEATSModel_84_12',\n",
    "        dropout=dropout,\n",
    "        **common_model_args,\n",
    "\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forecast(model, predict_after_series = val, variable  = 'dust', forecast_type = 'backtest', n = 84, forecast_horizon = 12):\n",
    "    result_accumulator = {}\n",
    "    print(f'For model {model.model_name}')\n",
    "    if forecast_type == 'backtest':\n",
    "        pred_series = model.historical_forecasts(series=full_series, \n",
    "                                        past_covariates=None,\n",
    "                                        future_covariates=None,\n",
    "                                        start = test.start_time(),\n",
    "                                        stride = forecast_horizon,\n",
    "                                        retrain=False,\n",
    "                                        verbose=False, \n",
    "                                        forecast_horizon=forecast_horizon,\n",
    "                                        last_points_only = False\n",
    "                                        )\n",
    "        pred_series = concatenate(pred_series)\n",
    "\n",
    "    else:\n",
    "        pred_series = model.predict(series=predict_after_series, n = n)\n",
    "    test_variable = test[variable]\n",
    "    pred_variable = pred_series[variable]\n",
    "    if variable != 'cloud':\n",
    "\n",
    "        result_accumulator[model.model_name] = {\n",
    "            \"mae\": mae(test_variable, pred_variable),\n",
    "            \"mse\": mse(test_variable, pred_variable),\n",
    "            \"mape\": mape(test_variable, pred_variable),\n",
    "            \"rmse\": rmse(test_variable, pred_variable)\n",
    "        }\n",
    "    else:\n",
    "        result_accumulator[model.model_name] = {\n",
    "            \"mae\": mae(test_variable, pred_variable),\n",
    "            \"mse\": mse(test_variable, pred_variable),\n",
    "            \"rmse\": rmse(test_variable, pred_variable)\n",
    "        }\n",
    "\n",
    "\n",
    "    return result_accumulator, pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(model, mlflow_run_id, test, pred_series, n = 84, type = 'backtest', variable = 'dust'):\n",
    "      all_artifacts = []\n",
    "      if type == 'backtest':\n",
    "            df_to_plot = pd.DataFrame({'Actual': scaler.inverse_transform(test)[variable].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig = df_to_plot.plot(title=f\"{variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig.show()\n",
    "            fig.write_image(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "\n",
    "            df_to_plot_zoom = pd.DataFrame({'Actual': scaler.inverse_transform(test)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series()})\n",
    "            fig2 = df_to_plot_zoom.plot(title=f\"Zoomed {variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig2.show()\n",
    "            fig2.write_image(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "      elif type == 'predict':\n",
    "            df_to_plot = pd.DataFrame({'Actual': scaler.inverse_transform(full_series[pd.Timestamp('2018-06-05T20:07:47'):])[variable].pd_series(), model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig = df_to_plot.plot(title=f\"{variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig.show()\n",
    "            fig.write_image(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}.png')\n",
    "\n",
    "            df_to_plot_zoom = pd.DataFrame({'Actual': scaler.inverse_transform(full_series)[variable][pd.Timestamp('2018-06-05T20:07:47'):pd.Timestamp('2018-07-31T11:09:27')].pd_series(), \n",
    "                                                model.model_name.split('_')[0]: scaler.inverse_transform(pred_series)[variable].pd_series()})\n",
    "            fig2 = df_to_plot_zoom.plot(title=f\"Zoomed {variable} {type}\", template=\"simple_white\",\n",
    "                  labels=dict(index=\"time\", value=variable, variable=\"Legend\"))\n",
    "            fig2.show()\n",
    "            fig2.write_image(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            # plt.savefig(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "            all_artifacts.append(f'../plots/{model.model_name}_{variable}_{type}_zoomed.png')\n",
    "\n",
    "      return all_artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models =    {'BlockRNNModel_84_12': create_block_rnn_model(),\n",
    "#                 'TCNModel_84_12': create_tcn_model(),\n",
    "#                 'TransformerModel_84_12': create_transformer_model(),\n",
    "#                 'NBEATSModel_84_12': create_n_beats_model(),\n",
    "#                   }\n",
    "\n",
    "# all_models =    {'BlockRNNModel_84_12': BlockRNNModel.load_from_checkpoint(model_name = \"BlockRNNModel_84_12\", best=True),\n",
    "#                 'TCNModel_84_12': TCNModel.load_from_checkpoint(model_name =\"TCNModel_84_12\", best=True),\n",
    "#                 'TransformerModel_84_12': TransformerModel.load_from_checkpoint(model_name =\"TransformerModel_84_12\", best=True),\n",
    "#                 'NBEATSModel_84_12': NBEATSModel.load_from_checkpoint(model_name =\"NBEATSModel_84_12\", best=True),\n",
    "#                   }\n",
    "\n",
    "# for model_name, model in all_models.items():\n",
    "#         # detect if a GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         num_workers = 8\n",
    "#     else:\n",
    "#         num_workers = 0\n",
    "\n",
    "#     series = create_series(dataframe)\n",
    "\n",
    "#     # when validating during training, we can use a slightly longer validation\n",
    "#     # set which also contains the first input_chunk_length time steps\n",
    "#     model_val_set = val\n",
    "\n",
    "#     # train the model\n",
    "#     model.fit(\n",
    "#         series=train,\n",
    "#         val_series=model_val_set,\n",
    "#         num_loader_workers=num_workers,\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.04043857, 'mse': 0.010832378, 'mape': 23.08908998966217, 'rmse': 0.10407871}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405a841652244e378b94dee3b09295c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.47711036, 'mse': 0.26179186, 'mape': 77.92339324951172, 'rmse': 0.511656}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.024764007, 'mse': 0.0011659008, 'mape': 11.06971725821495, 'rmse': 0.034145292}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5629c959626f4995b847add4dc22c989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.117779106, 'mse': 0.017748294, 'mape': 27.09687650203705, 'rmse': 0.13322273}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.027591374, 'mse': 0.0016589984, 'mape': 6.019645184278488, 'rmse': 0.040730804}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63c184125174689ac1988edf6d9b29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.06572796, 'mse': 0.0060510347, 'mape': 23.238804936408997, 'rmse': 0.0777884}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.024159865, 'mse': 0.0010927896, 'rmse': 0.03305737}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9c90c855c645c7a64c803db9a5b48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.025491558, 'mse': 0.0009030749, 'rmse': 0.030051205}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.014787294, 'mse': 0.00042018617, 'mape': 5.606592074036598, 'rmse': 0.020498443}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005c7d9c5b464f24b1a72a7bbe4857bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.027054701, 'mse': 0.0010432762, 'mape': 9.633656591176987, 'rmse': 0.032299787}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.06462918, 'mse': 0.008134814, 'mape': 16.665704548358917, 'rmse': 0.090193205}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b704827f8a4f3eb597e2b4a2a1e7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.09552282, 'mse': 0.015635582, 'mape': 22.75327891111374, 'rmse': 0.12504232}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.045111116, 'mse': 0.0038368574, 'mape': 9.183912724256516, 'rmse': 0.061942372}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf85330dbe74d318518629f7a1e84b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.06915828, 'mse': 0.007721337, 'mape': 15.543611347675323, 'rmse': 0.08787114}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.040898643, 'mse': 0.002821805, 'mape': 8.394428342580795, 'rmse': 0.053120665}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_backtest.csv\n",
      "For model BlockRNNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39314c6ead648c0832a86529bd586c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BlockRNNModel_84_12': {'mae': 0.1528706, 'mse': 0.029022373, 'mape': 20.323142409324646, 'rmse': 0.17035954}}\n",
      "Going to save predictions of model BlockRNNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/BlockRNNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.040521283, 'mse': 0.01114268, 'mape': 27.84445881843567, 'rmse': 0.105558895}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82274a3ccb42437ebe0a28b2e5e27a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.47869024, 'mse': 0.264738, 'mape': 77.86687016487122, 'rmse': 0.51452696}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.0060271346, 'mse': 0.00011974169, 'mape': 2.539270929992199, 'rmse': 0.010942655}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dbe6b3eb754d9f8c1b2d8f128274ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.091665305, 'mse': 0.01061859, 'mape': 20.504721999168396, 'rmse': 0.103046544}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.013014884, 'mse': 0.00029517416, 'mape': 2.672090195119381, 'rmse': 0.017180633}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d23cae1c6d42269dca028de1c01bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.050964423, 'mse': 0.0049127983, 'mape': 19.724009931087494, 'rmse': 0.07009136}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.03232136, 'mse': 0.0016458227, 'rmse': 0.04056874}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b33391e477a4252a35635075d84caf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.016253602, 'mse': 0.0002924553, 'rmse': 0.017101325}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.011832757, 'mse': 0.00027720802, 'mape': 4.563497379422188, 'rmse': 0.016649565}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5885554de114f66a48d412a76fad119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.020622298, 'mse': 0.0007880973, 'mape': 7.166147977113724, 'rmse': 0.02807307}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.061245296, 'mse': 0.0058382554, 'mape': 15.247796475887299, 'rmse': 0.076408476}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2407f7889b53499aa8ba910571ea8450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.088278115, 'mse': 0.012863205, 'mape': 20.293110609054565, 'rmse': 0.11341607}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.03344531, 'mse': 0.002378435, 'mape': 7.2022005915641785, 'rmse': 0.048769202}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f530be9e4274ecca6e0debc52a9e37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.06876411, 'mse': 0.009212097, 'mape': 16.210491955280304, 'rmse': 0.09597967}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.041341297, 'mse': 0.0027147701, 'mape': 8.592583984136581, 'rmse': 0.052103456}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_backtest.csv\n",
      "For model TCNModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5c75050685436a8e5cb16409b5f94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TCNModel_84_12': {'mae': 0.14832702, 'mse': 0.026503418, 'mape': 19.828324019908905, 'rmse': 0.1627987}}\n",
      "Going to save predictions of model TCNModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TCNModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.04307562, 'mse': 0.010092018, 'mape': 28.457099199295044, 'rmse': 0.10045904}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b267819a41402b9bf4ff11ae8853f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.48727694, 'mse': 0.27396363, 'mape': 79.30952906608582, 'rmse': 0.5234153}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.028058423, 'mse': 0.0013121906, 'mape': 14.253784716129303, 'rmse': 0.03622417}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3852e70e7747e8b23b37a65386e1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.11961879, 'mse': 0.018679198, 'mape': 28.99518609046936, 'rmse': 0.13667186}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.027852139, 'mse': 0.0016685247, 'mape': 6.0112472623586655, 'rmse': 0.040847577}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c2ee82b27a470d9784107fa3037d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.07315775, 'mse': 0.0073586497, 'mape': 23.947806656360626, 'rmse': 0.08578257}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.02704156, 'mse': 0.0013472924, 'rmse': 0.036705483}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4bee457c704b6594dc48b5a49aad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.011589389, 'mse': 0.00018211042, 'rmse': 0.01349483}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.017419957, 'mse': 0.00048301983, 'mape': 6.883179396390915, 'rmse': 0.021977711}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7afd420cf64cecaff5e8ab975a8ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.015191992, 'mse': 0.00033195465, 'mape': 5.130632221698761, 'rmse': 0.018219622}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.06049103, 'mse': 0.007419187, 'mape': 15.421667695045471, 'rmse': 0.0861347}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7e50bfb142490ea9ba038f8182378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.0913716, 'mse': 0.014885163, 'mape': 21.108238399028778, 'rmse': 0.12200477}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.046785027, 'mse': 0.0039440994, 'mape': 9.487319737672806, 'rmse': 0.06280207}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6868f3e1512d4c3aa2dc5dbdb538c17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.0750399, 'mse': 0.009917955, 'mape': 17.306305468082428, 'rmse': 0.09958893}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.0406086, 'mse': 0.0028210657, 'mape': 8.50706622004509, 'rmse': 0.053113706}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_backtest.csv\n",
      "For model TransformerModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bf0bb46dba48b88f6cb8583a2607db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TransformerModel_84_12': {'mae': 0.15102096, 'mse': 0.028686296, 'mape': 20.027008652687073, 'rmse': 0.1693703}}\n",
      "Going to save predictions of model TransformerModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/TransformerModel_84_12_predict.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.042682283, 'mse': 0.012543831, 'mape': 32.12507963180542, 'rmse': 0.11199924}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c03a82b1bee4020909533c72d4cd733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.48003474, 'mse': 0.2665723, 'mape': 77.99035310745239, 'rmse': 0.5163064}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.018798763, 'mse': 0.0006668286, 'mape': 8.710120618343353, 'rmse': 0.025823025}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779ab82c8f344f8baa33fc017cf898fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.12916571, 'mse': 0.020753566, 'mape': 28.390827775001526, 'rmse': 0.14406098}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.032100983, 'mse': 0.0016309256, 'mape': 6.161771342158318, 'rmse': 0.04038472}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12392cfc30d4c2db7aaf0d5b163c276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.06554564, 'mse': 0.0060869358, 'mape': 22.240349650382996, 'rmse': 0.078018814}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.024252247, 'mse': 0.0010775971, 'rmse': 0.032826774}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4185d70642f44f479af46cd516ac2e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.014928525, 'mse': 0.00032813888, 'rmse': 0.018114604}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.021512885, 'mse': 0.0007325208, 'mape': 8.133912831544876, 'rmse': 0.027065123}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f2856211840a8830e580bfb2ece9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.013873008, 'mse': 0.0002997911, 'mape': 4.664641246199608, 'rmse': 0.017314477}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.05345306, 'mse': 0.005633303, 'mape': 13.761498034000397, 'rmse': 0.07505533}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f9dca9826444c991ae08ea042de2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.09346444, 'mse': 0.017537965, 'mape': 23.6727237701416, 'rmse': 0.13243099}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.037873566, 'mse': 0.0027800684, 'mape': 7.700509577989578, 'rmse': 0.052726354}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f661200e0d814614aeda602ed5b43952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.0546584, 'mse': 0.004687348, 'mape': 11.488060653209686, 'rmse': 0.06846421}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.046962712, 'mse': 0.0035104791, 'mape': 9.997031837701797, 'rmse': 0.059249297}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_backtest.csv\n",
      "For model NBEATSModel_84_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/OpenMars/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c2178731624a6e9fff987fce91f0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NBEATSModel_84_12': {'mae': 0.16463897, 'mse': 0.0314946, 'mape': 22.30733186006546, 'rmse': 0.17746718}}\n",
      "Going to save predictions of model NBEATSModel_84_12 to file /home/ubuntu/OpenMarsML/data/predicted_data/NBEATSModel_84_12_predict.csv\n"
     ]
    }
   ],
   "source": [
    "trained_models =    {'BlockRNNModel_84_12': BlockRNNModel.load_from_checkpoint(model_name = \"BlockRNNModel_84_12\", best=True),\n",
    "                'TCNModel_84_12': TCNModel.load_from_checkpoint(model_name =\"TCNModel_84_12\", best=True),\n",
    "                'TransformerModel_84_12': TransformerModel.load_from_checkpoint(model_name =\"TransformerModel_84_12\", best=True),\n",
    "                'NBEATSModel_84_12': NBEATSModel.load_from_checkpoint(model_name =\"NBEATSModel_84_12\", best=True),\n",
    "                  }\n",
    "\n",
    "all_variables = ['dust', 'Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'temp']\n",
    "\n",
    "types = ['backtest', 'predict']\n",
    "for model_name, model in trained_models.items():\n",
    "    with mlflow.start_run(run_name=model.model_name) as run:\n",
    "        all_artifacts = []\n",
    "        mlflow.set_tag(\"Model_Name\", model.model_name)\n",
    "        mlflow.log_params(model.model_params)\n",
    "        for variable in all_variables:\n",
    "            for type in types:\n",
    "                if type == 'predict':\n",
    "                    series = full_series[:pd.Timestamp('2018-06-05T20:07:47')]\n",
    "                    eval_results, pred_series = forecast(model, predict_after_series=series,\n",
    "                                                          variable=variable, forecast_type=type)\n",
    "                else:\n",
    "                    series = test\n",
    "                    eval_results, pred_series = forecast(model, predict_after_series=series,\n",
    "                                                          variable=variable, forecast_type=type)\n",
    "                print(eval_results)\n",
    "                for model_mm, res in eval_results.items():\n",
    "                    mlflow.log_metrics(res)\n",
    "                # artifacts = plotting(model, run.info.run_id, test, pred_series, type = type,  variable = variable)\n",
    "                # all_artifacts.extend(artifacts)\n",
    "                columns = ['Tsurf', 'Psurf', 'cloud', 'vapour', 'u_wind', 'v_wind', 'dust', 'temp']\n",
    "                predict_df = scaler.inverse_transform(pred_series).pd_dataframe()\n",
    "                predicted_file_nm =f'{model.model_name}_{type}'\n",
    "                final_path = f'/home/ubuntu/OpenMarsML/data/predicted_data/{predicted_file_nm}.csv'\n",
    "                print(f'Going to save predictions of model {model.model_name} to file {final_path}')\n",
    "                predict_df.to_csv(final_path)\n",
    "\n",
    "        # for artifact in all_artifacts:\n",
    "        #     print(artifact)\n",
    "        #     mlflow.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_to_predict = full_series[:pd.Timestamp('2018-06-05T20:07:47')]\n",
    "# series_predicted_actual = full_series[:pd.Timestamp('2018-06-05 22:11:01')]\n",
    "# final_path = f'/home/ubuntu/OpenMarsML/data/data_files/series_to_predict.csv'\n",
    "# series_to_predict.to_csv(f'/home/ubuntu/OpenMarsML/data/data_files/series_to_predict.csv')\n",
    "# series_predicted_actual.to_csv(f'/home/ubuntu/OpenMarsML/data/data_files/predicted_series_actual_vals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
